package services

import (
	"crypto/md5"
	"database/sql"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"log"
	"mime/multipart"
	"net/http"
	"os"
	"path/filepath"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"

	"pica-comic-server/models"

	"github.com/google/uuid"
	_ "github.com/mattn/go-sqlite3"
)

var (
	downloadManager *DownloadManager
	once            sync.Once
)

// DownloadManager ä¸‹è½½ç®¡ç†å™¨
type DownloadManager struct {
	mu            sync.RWMutex
	downloadPath  string
	db            *sql.DB
	queue         []*models.DownloadTask
	isDownloading bool
	currentTask   *models.DownloadTask
	stopChan      chan bool
	minDiskSpace  int64
}

// InitDownloadManager åˆå§‹åŒ–ä¸‹è½½ç®¡ç†å™¨
func InitDownloadManager(downloadPath string) error {
	var initErr error
	once.Do(func() {
		downloadManager = &DownloadManager{
			downloadPath: downloadPath,
			queue:        make([]*models.DownloadTask, 0),
			stopChan:     make(chan bool, 1), // ç¼“å†²ä¸º1ï¼Œé¿å… Pause() é˜»å¡
			minDiskSpace: 200 * 1024 * 1024,
		}
		initErr = downloadManager.init()
	})
	return initErr
}

// GetDownloadManager è·å–ä¸‹è½½ç®¡ç†å™¨å®ä¾‹
func GetDownloadManager() *DownloadManager {
	return downloadManager
}

func (dm *DownloadManager) init() error {
	if err := dm.ensureDownloadDir(); err != nil {
		return err
	}

	// æ‰“å¼€æ•°æ®åº“
	dbPath := filepath.Join(dm.downloadPath, "download.db")
	db, err := sql.Open("sqlite3", dbPath)
	if err != nil {
		return fmt.Errorf("æ‰“å¼€æ•°æ®åº“å¤±è´¥: %w", err)
	}
	dm.db = db

	// åˆ›å»ºè¡¨
	if err := dm.createTables(); err != nil {
		return fmt.Errorf("åˆ›å»ºæ•°æ®è¡¨å¤±è´¥: %w", err)
	}

	// è¿è¡Œæ•°æ®åº“è¿ç§»
	if err := dm.migrateTables(); err != nil {
		return fmt.Errorf("æ•°æ®åº“è¿ç§»å¤±è´¥: %w", err)
	}

	// åŠ è½½æœªå®Œæˆçš„ä»»åŠ¡
	if err := dm.loadPendingTasks(); err != nil {
		return fmt.Errorf("åŠ è½½å¾…å¤„ç†ä»»åŠ¡å¤±è´¥: %w", err)
	}

	return nil
}

// migrateTables æ‰§è¡Œæ•°æ®åº“è¿ç§»
func (dm *DownloadManager) migrateTables() error {
	// æ£€æŸ¥ comics è¡¨æ˜¯å¦æœ‰ detail_url åˆ—
	var columnExists bool
	err := dm.db.QueryRow(`
		SELECT COUNT(*) > 0 
		FROM pragma_table_info('comics') 
		WHERE name='detail_url'
	`).Scan(&columnExists)

	if err != nil {
		return fmt.Errorf("æ£€æŸ¥ detail_url åˆ—å¤±è´¥: %w", err)
	}

	// å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œæ·»åŠ å®ƒ
	if !columnExists {
		log.Println("[Migration] æ·»åŠ  detail_url åˆ—åˆ° comics è¡¨")
		_, err = dm.db.Exec(`ALTER TABLE comics ADD COLUMN detail_url TEXT`)
		if err != nil {
			return fmt.Errorf("æ·»åŠ  detail_url åˆ—å¤±è´¥: %w", err)
		}
		log.Println("[Migration] âœ“ detail_url åˆ—æ·»åŠ æˆåŠŸ")
	}

	return nil
}

// ensureDownloadDir ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
func (dm *DownloadManager) ensureDownloadDir() error {
	if err := os.MkdirAll(dm.downloadPath, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºä¸‹è½½ç›®å½•å¤±è´¥: %w", err)
	}
	return nil
}

// ensureDiskSpace æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³
func (dm *DownloadManager) ensureDiskSpace() error {
	// è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„ç£ç›˜ç©ºé—´æ£€æŸ¥é€»è¾‘
	// æš‚æ—¶åªè¿”å› nil
	return nil
}

func (dm *DownloadManager) createTables() error {
	// ä¸‹è½½çš„æ¼«ç”»è¡¨
	_, err := dm.db.Exec(`
		CREATE TABLE IF NOT EXISTS comics (
			id TEXT PRIMARY KEY,
			title TEXT NOT NULL,
			author TEXT,
			description TEXT,
			cover TEXT,
			tags TEXT,
			categories TEXT,
			eps_count INTEGER,
			pages_count INTEGER,
			type TEXT,
			time INTEGER,
			size INTEGER,
			directory TEXT,
			eps TEXT,
			downloaded_eps TEXT,
			detail_url TEXT
		)
	`)
	if err != nil {
		return err
	}

	// ä¸‹è½½ä»»åŠ¡è¡¨
	_, err = dm.db.Exec(`
		CREATE TABLE IF NOT EXISTS download_tasks (
			id TEXT PRIMARY KEY,
			comic_id TEXT NOT NULL,
			title TEXT NOT NULL,
			type TEXT NOT NULL,
			cover TEXT,
			total_pages INTEGER,
			downloaded_pages INTEGER,
			current_ep INTEGER,
			status TEXT,
			error TEXT,
			created_at INTEGER,
			updated_at INTEGER,
			description TEXT,
			extra TEXT,
			tags TEXT,
			author TEXT
		)
	`)
	return err
}

func (dm *DownloadManager) loadPendingTasks() error {
	rows, err := dm.db.Query(`
		SELECT id, comic_id, title, type, cover, total_pages, downloaded_pages, 
		       current_ep, status, error, created_at, updated_at,
		       COALESCE(description, ''), COALESCE(extra, ''), COALESCE(tags, ''), COALESCE(author, '')
		FROM download_tasks
		WHERE status IN ('pending', 'downloading', 'paused')
		ORDER BY created_at
	`)
	if err != nil {
		return err
	}
	defer rows.Close()

	for rows.Next() {
		task := &models.DownloadTask{}
		var createdAt, updatedAt int64
		err := rows.Scan(
			&task.ID, &task.ComicID, &task.Title, &task.Type, &task.Cover,
			&task.TotalPages, &task.DownloadedPages, &task.CurrentEp,
			&task.Status, &task.Error, &createdAt, &updatedAt,
			&task.Description, &task.Extra, &task.Tags, &task.Author,
		)
		if err != nil {
			continue
		}
		task.CreatedAt = time.Unix(createdAt, 0)
		task.UpdatedAt = time.Unix(updatedAt, 0)
		dm.queue = append(dm.queue, task)
	}

	return nil
}

// AddDownloadTask æ·»åŠ ä¸‹è½½ä»»åŠ¡
func (dm *DownloadManager) AddDownloadTask(req models.DownloadRequest) (*models.DownloadTask, error) {
	dm.mu.Lock()
	defer dm.mu.Unlock()

	if err := dm.ensureDiskSpace(); err != nil {
		return nil, err
	}

	tagsJSON, _ := json.Marshal(req.Tags)
	extraJSON, _ := json.Marshal(req.Extra)

	task := &models.DownloadTask{
		ID:              uuid.New().String(),
		ComicID:         req.ComicID,
		Type:            req.Type,
		Status:          "pending",
		DownloadedPages: 0,
		CurrentEp:       0,
		Title:           req.Title,
		Author:          req.Author,
		Cover:           req.Cover,
		TotalPages:      len(req.Eps),
		CreatedAt:       time.Now(),
		UpdatedAt:       time.Now(),
		Description:     req.Description,
		Extra:           string(extraJSON),
		Tags:            string(tagsJSON),
	}

	// ä¿å­˜åˆ°æ•°æ®åº“
	_, err := dm.db.Exec(`
		INSERT INTO download_tasks 
		(id, comic_id, title, type, cover, total_pages, downloaded_pages, 
		 current_ep, status, error, created_at, updated_at, description, extra, tags, author)
		VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `, task.ID, task.ComicID, task.Title, task.Type, task.Cover,
		task.TotalPages, task.DownloadedPages, task.CurrentEp,
		task.Status, task.Error, task.CreatedAt.Unix(), task.UpdatedAt.Unix(),
		task.Description, task.Extra, task.Tags, task.Author)

	if err != nil {
		return nil, err
	}

	dm.queue = append(dm.queue, task)

	// å¦‚æœæ²¡æœ‰æ­£åœ¨ä¸‹è½½çš„ä»»åŠ¡ï¼Œè‡ªåŠ¨å¼€å§‹
	if !dm.isDownloading {
		go dm.processQueue()
	}

	return task, nil
}

// GetDownloadQueue è·å–ä¸‹è½½é˜Ÿåˆ—
func (dm *DownloadManager) GetDownloadQueue() []*models.DownloadTask {
	dm.mu.RLock()
	defer dm.mu.RUnlock()
	return dm.queue
}

// Start å¼€å§‹ä¸‹è½½
func (dm *DownloadManager) Start() error {
	dm.mu.Lock()
	defer dm.mu.Unlock()

	if dm.isDownloading {
		return fmt.Errorf("å·²ç»åœ¨ä¸‹è½½ä¸­")
	}

	if len(dm.queue) == 0 {
		return fmt.Errorf("ä¸‹è½½é˜Ÿåˆ—ä¸ºç©º")
	}

	go dm.processQueue()
	return nil
}

// Pause æš‚åœä¸‹è½½
func (dm *DownloadManager) Pause() {
	dm.mu.Lock()
	defer dm.mu.Unlock()

	if dm.isDownloading {
		dm.stopChan <- true
		dm.isDownloading = false
		if dm.currentTask != nil {
			dm.currentTask.Status = "paused"
			dm.updateTaskStatus(dm.currentTask)
		}
	}
}

// IsDownloading æ˜¯å¦æ­£åœ¨ä¸‹è½½
func (dm *DownloadManager) IsDownloading() bool {
	dm.mu.RLock()
	defer dm.mu.RUnlock()
	return dm.isDownloading
}

// CancelTask å–æ¶ˆä»»åŠ¡
func (dm *DownloadManager) CancelTask(taskID string) error {
	dm.mu.Lock()
	defer dm.mu.Unlock()

	for i, task := range dm.queue {
		if task.ID == taskID {
			// ä»é˜Ÿåˆ—ä¸­ç§»é™¤
			dm.queue = append(dm.queue[:i], dm.queue[i+1:]...)

			// ä»æ•°æ®åº“åˆ é™¤
			_, err := dm.db.Exec("DELETE FROM download_tasks WHERE id = ?", taskID)
			return err
		}
	}

	return fmt.Errorf("ä»»åŠ¡ä¸å­˜åœ¨")
}

// processQueue å¤„ç†ä¸‹è½½é˜Ÿåˆ—
func (dm *DownloadManager) processQueue() {
	dm.mu.Lock()
	dm.isDownloading = true
	dm.mu.Unlock()

	defer func() {
		dm.mu.Lock()
		dm.isDownloading = false
		dm.currentTask = nil
		dm.mu.Unlock()
	}()

	for {
		dm.mu.Lock()
		if len(dm.queue) == 0 {
			dm.mu.Unlock()
			break
		}

		task := dm.queue[0]
		dm.currentTask = task
		dm.mu.Unlock()

		// ä¸‹è½½ä»»åŠ¡
		task.Status = "downloading"
		dm.updateTaskStatus(task)

		if err := dm.downloadTask(task); err != nil {
			task.Status = "error"
			task.Error = err.Error()
			dm.updateTaskStatus(task)
			fmt.Printf("ä¸‹è½½å¤±è´¥: %s - %v\n", task.Title, err)
		} else {
			task.Status = "completed"
			dm.updateTaskStatus(task)
			fmt.Printf("ä¸‹è½½å®Œæˆ: %s\n", task.Title)
		}

		// ä»é˜Ÿåˆ—ç§»é™¤
		dm.mu.Lock()
		dm.queue = dm.queue[1:]
		dm.mu.Unlock()

		// æ£€æŸ¥æ˜¯å¦æ”¶åˆ°åœæ­¢ä¿¡å·
		select {
		case <-dm.stopChan:
			return
		default:
		}
	}
}

// downloadTask ä¸‹è½½å•ä¸ªä»»åŠ¡
func (dm *DownloadManager) downloadTask(task *models.DownloadTask) error {
	// ğŸ†• æ‰€æœ‰ä¸‹è½½éƒ½ä½¿ç”¨ç›´æ¥ä¸‹è½½æ¨¡å¼ï¼ˆå®¢æˆ·ç«¯æ‹¦æˆª URLï¼‰
	var extraCheck struct {
		DirectMode bool `json:"direct_mode"`
	}
	json.Unmarshal([]byte(task.Extra), &extraCheck)

	if !extraCheck.DirectMode {
		return fmt.Errorf("ä»…æ”¯æŒç›´æ¥ä¸‹è½½æ¨¡å¼ï¼Œè¯·ä½¿ç”¨å®¢æˆ·ç«¯æ‹¦æˆª URL åå‘é€åˆ°æœåŠ¡å™¨")
	}

	fmt.Printf("[ä»»åŠ¡è°ƒåº¦] ä½¿ç”¨ç›´æ¥ä¸‹è½½æ¨¡å¼\n")
	return dm.downloadDirectComic(task)
}

// getImageHeaders æ ¹æ®æ¼«ç”»ç±»å‹è·å–å›¾ç‰‡ä¸‹è½½è¯·æ±‚å¤´
func (dm *DownloadManager) getImageHeaders(comicType string, url string) map[string]string {
	headers := make(map[string]string)

	switch comicType {
	case "picacg":
		// Picacg å›¾ç‰‡éœ€è¦ç‰¹å®šçš„è¯·æ±‚å¤´
		headers["User-Agent"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
		headers["Referer"] = "https://www.picacomic.com/"
		// Picacgå›¾ç‰‡é€šè¿‡å…¶CDNæä¾›ï¼Œé€šå¸¸ä¸éœ€è¦ç‰¹æ®Šè®¤è¯

	case "jm":
		// JM å›¾ç‰‡è¯·æ±‚å¤´ï¼ˆæ›´å®Œæ•´çš„æµè§ˆå™¨è¯·æ±‚å¤´ï¼‰
		headers["User-Agent"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
		headers["Referer"] = "https://18comic.vip/"
		headers["Accept"] = "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8"
		headers["Accept-Language"] = "zh-CN,zh;q=0.9,en;q=0.8"
		headers["Accept-Encoding"] = "gzip, deflate, br"
		headers["Sec-Fetch-Dest"] = "image"
		headers["Sec-Fetch-Mode"] = "no-cors"
		headers["Sec-Fetch-Site"] = "cross-site"

	case "ehentai":
		// EHentai å›¾ç‰‡è¯·æ±‚å¤´
		headers["User-Agent"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
		headers["Referer"] = "https://e-hentai.org/"
		// EHentaiå›¾ç‰‡æœåŠ¡å™¨å¯èƒ½åœ¨ ehgt.org

	case "hitomi":
		// Hitomi å›¾ç‰‡è¯·æ±‚å¤´
		headers["User-Agent"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
		headers["Referer"] = "https://hitomi.la/"

	case "nhentai":
		// NHentai å›¾ç‰‡è¯·æ±‚å¤´
		headers["User-Agent"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
		headers["Referer"] = "https://nhentai.net/"

	case "htmanga", "htManga":
		// HTManga å›¾ç‰‡è¯·æ±‚å¤´
		headers["User-Agent"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
		headers["Referer"] = "https://htmanga.com/"

	default:
		// é»˜è®¤è¯·æ±‚å¤´
		headers["User-Agent"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
	}

	return headers
}

// downloadFileWithHeaders ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒè‡ªå®šä¹‰è¯·æ±‚å¤´å’Œé‡è¯•ï¼‰
func (dm *DownloadManager) downloadFileWithHeaders(url, filePath string, headers map[string]string) error {
	maxRetries := 3
	var lastErr error

	for attempt := 1; attempt <= maxRetries; attempt++ {
		err := dm.downloadFileOnce(url, filePath, headers)
		if err == nil {
			return nil
		}

		lastErr = err
		if attempt < maxRetries {
			waitTime := time.Duration(attempt) * time.Second
			fmt.Printf("[é‡è¯•] ä¸‹è½½å¤±è´¥ï¼Œ%dç§’åé‡è¯• (ç¬¬ %d/%d æ¬¡): %v\n", waitTime/time.Second, attempt, maxRetries, err)
			time.Sleep(waitTime)
		}
	}

	return fmt.Errorf("ä¸‹è½½å¤±è´¥ï¼ˆå·²é‡è¯• %d æ¬¡ï¼‰: %w", maxRetries, lastErr)
}

// downloadFileOnce ä¸‹è½½æ–‡ä»¶ï¼ˆå•æ¬¡å°è¯•ï¼‰
func (dm *DownloadManager) downloadFileOnce(url, filePath string, headers map[string]string) error {
	req, err := http.NewRequest("GET", url, nil)
	if err != nil {
		return err
	}

	// è®¾ç½®é»˜è®¤è¯·æ±‚å¤´
	if headers == nil {
		headers = make(map[string]string)
	}
	if _, ok := headers["User-Agent"]; !ok {
		headers["User-Agent"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
	}

	for k, v := range headers {
		req.Header.Set(k, v)
	}

	// è®¾ç½®è¶…æ—¶
	client := &http.Client{
		Timeout: 30 * time.Second,
	}

	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç  %d: %s", resp.StatusCode, string(body))
	}

	if err := os.MkdirAll(filepath.Dir(filePath), 0755); err != nil {
		return err
	}

	file, err := os.Create(filePath)
	if err != nil {
		return err
	}
	defer file.Close()

	_, err = io.Copy(file, resp.Body)
	return err
}

// parseTags è§£ææ ‡ç­¾ JSONï¼Œè¿”å›æ‰€æœ‰æ ‡ç­¾å’Œåˆ†ç±»
func parseTags(tagsJSON string) (allTags []string, categories []string) {
	if tagsJSON == "" {
		return nil, nil
	}
	var tagsMap map[string][]string
	if err := json.Unmarshal([]byte(tagsJSON), &tagsMap); err != nil {
		return nil, nil
	}

	allTags = make([]string, 0)
	categories = make([]string, 0)

	for key, list := range tagsMap {
		// æå–åˆ†ç±»ï¼ˆcategory/categoriesé”®ï¼‰
		if key == "category" || key == "categories" {
			categories = append(categories, list...)
		}
		// æ‰€æœ‰æ ‡ç­¾éƒ½åŠ å…¥åˆ°allTags
		allTags = append(allTags, list...)
	}

	return allTags, categories
}

// updateTaskStatus æ›´æ–°ä»»åŠ¡çŠ¶æ€
func (dm *DownloadManager) updateTaskStatus(task *models.DownloadTask) {
	task.UpdatedAt = time.Now()
	_, _ = dm.db.Exec(`
		UPDATE download_tasks 
		SET status = ?, error = ?, downloaded_pages = ?, current_ep = ?, total_pages = ?, updated_at = ?
		WHERE id = ?
	`, task.Status, task.Error, task.DownloadedPages, task.CurrentEp, task.TotalPages,
		task.UpdatedAt.Unix(), task.ID)
}

// generateComicID ä¸ºæ–‡ä»¶å¤¹ç”Ÿæˆç¨³å®šçš„ID
func generateComicID(folderName string) string {
	// ä½¿ç”¨MD5å“ˆå¸Œç”Ÿæˆç¨³å®šçš„ID
	hash := md5.Sum([]byte(folderName))
	return fmt.Sprintf("scanned_%x", hash[:8]) // ä½¿ç”¨å‰8å­—èŠ‚ï¼Œè¶³å¤Ÿå”¯ä¸€
}

// GetAllComics è·å–æ‰€æœ‰å·²ä¸‹è½½çš„æ¼«ç”»ï¼ˆåŒ…æ‹¬æ‰«ææ–‡ä»¶å¤¹ï¼‰
func (dm *DownloadManager) GetAllComics() ([]models.ComicDetail, error) {
	// 1. ä»æ•°æ®åº“è¯»å–å·²è®°å½•çš„æ¼«ç”»
	comicMap := make(map[string]*models.ComicDetail)

	rows, err := dm.db.Query(`
		SELECT id, title, author, description, cover, tags, categories,
		       eps_count, pages_count, type, time, size, directory, eps, downloaded_eps, detail_url
		FROM comics
		ORDER BY time DESC
	`)
	if err == nil {
		defer rows.Close()
		for rows.Next() {
			var comic models.ComicDetail
			var tagsJSON, categoriesJSON, epsJSON, downloadedEpsJSON string
			var timeUnix int64

			err := rows.Scan(
				&comic.ID, &comic.Title, &comic.Author, &comic.Description,
				&comic.Cover, &tagsJSON, &categoriesJSON, &comic.EpsCount,
				&comic.PagesCount, &comic.Type, &timeUnix, &comic.Size,
				&comic.Directory, &epsJSON, &downloadedEpsJSON, &comic.DetailURL,
			)
			if err == nil {
				// ç¡®ä¿å³ä½¿JSONä¸ºç©ºä¹Ÿåˆå§‹åŒ–ä¸ºç©ºæ•°ç»„
				if tagsJSON != "" {
					json.Unmarshal([]byte(tagsJSON), &comic.Tags)
				}
				if comic.Tags == nil {
					comic.Tags = []string{}
				}

				if categoriesJSON != "" {
					json.Unmarshal([]byte(categoriesJSON), &comic.Categories)
				}
				if comic.Categories == nil {
					comic.Categories = []string{}
				}

				if epsJSON != "" {
					json.Unmarshal([]byte(epsJSON), &comic.Eps)
				}
				if comic.Eps == nil {
					comic.Eps = []string{}
				}

				if downloadedEpsJSON != "" {
					json.Unmarshal([]byte(downloadedEpsJSON), &comic.DownloadedEps)
				}
				if comic.DownloadedEps == nil {
					comic.DownloadedEps = []int{}
				}

				comic.Time = time.Unix(timeUnix, 0)
				comicMap[comic.Directory] = &comic
			}
		}
	}

	// 2. æ‰«æä¸‹è½½ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶å¤¹
	entries, err := os.ReadDir(dm.downloadPath)
	if err != nil {
		// å¦‚æœæ‰«æå¤±è´¥ï¼Œè¿”å›æ•°æ®åº“ä¸­çš„æ¼«ç”»
		var comics []models.ComicDetail
		for _, comic := range comicMap {
			comics = append(comics, *comic)
		}
		return comics, nil
	}

	dirSet := make(map[string]bool)
	for _, entry := range entries {
		if entry.IsDir() {
			dirName := entry.Name()
			dirSet[dirName] = true

			// å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ­¤æ–‡ä»¶å¤¹çš„è®°å½•ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬è®°å½•
			if _, exists := comicMap[dirName]; !exists {
				info, _ := entry.Info()
				modTime := time.Now()
				if info != nil {
					modTime = info.ModTime()
				}

				// æ‰«æç« èŠ‚
				eps, downloadedEps := dm.scanComicFolder(filepath.Join(dm.downloadPath, dirName))

				// ä¸ºæ‰«æçš„æ¼«ç”»ç”Ÿæˆç¨³å®šçš„ID
				scannedID := generateComicID(dirName)

				// è®¡ç®—æ–‡ä»¶å¤¹å¤§å°
				folderPath := filepath.Join(dm.downloadPath, dirName)
				folderSize := calculateFolderSize(folderPath)

				comicMap[dirName] = &models.ComicDetail{
					Comic: models.Comic{
						ID:          scannedID, // ä½¿ç”¨å“ˆå¸Œç”Ÿæˆçš„ç¨³å®šID
						Title:       dirName,
						Author:      "æœªçŸ¥",
						Description: "ä»æ–‡ä»¶å¤¹æ‰«æçš„æ¼«ç”»",
						Tags:        []string{},
						Categories:  []string{},
						Type:        "server", // æœåŠ¡å™¨æ¼«ç”»
						EpsCount:    len(eps),
						PagesCount:  0,          // é¡µæ•°åœ¨é˜…è¯»æ—¶åŠ¨æ€è·å–
						Size:        folderSize, // è®¡ç®—çš„å®é™…å¤§å°ï¼ˆå­—èŠ‚ï¼‰
						Time:        modTime,
					},
					Directory:     dirName,
					Eps:           eps,
					DownloadedEps: downloadedEps,
				}
			}
		}
	}

	// 3. è½¬æ¢ä¸ºåˆ‡ç‰‡å¹¶è¿”å›
	var comics []models.ComicDetail
	for _, comic := range comicMap {
		comics = append(comics, *comic)
	}

	return comics, nil
}

// scanComicFolder æ‰«ææ¼«ç”»æ–‡ä»¶å¤¹ï¼Œè·å–ç« èŠ‚ä¿¡æ¯
func (dm *DownloadManager) scanComicFolder(folderPath string) ([]string, []int) {
	var eps []string
	var downloadedEps []int

	entries, err := os.ReadDir(folderPath)
	if err != nil {
		return eps, downloadedEps
	}

	for _, entry := range entries {
		if entry.IsDir() {
			// å°è¯•å°†æ–‡ä»¶å¤¹åè½¬æ¢ä¸ºæ•°å­—ï¼ˆç« èŠ‚åºå·ï¼‰
			if epNum, err := strconv.Atoi(entry.Name()); err == nil {
				eps = append(eps, fmt.Sprintf("ç¬¬ %d è¯", epNum))
				downloadedEps = append(downloadedEps, epNum)
			}
		}
	}

	// æ’åº
	sort.Ints(downloadedEps)

	return eps, downloadedEps
}

// GetComic è·å–æ¼«ç”»è¯¦æƒ…
func (dm *DownloadManager) GetComic(id string) (*models.ComicDetail, error) {
	var comic models.ComicDetail
	var tagsJSON, categoriesJSON, epsJSON, downloadedEpsJSON string
	var timeUnix int64

	err := dm.db.QueryRow(`
		SELECT id, title, author, description, cover, tags, categories,
		       eps_count, pages_count, type, time, size, directory, eps, downloaded_eps, detail_url
		FROM comics WHERE id = ?
	`, id).Scan(
		&comic.ID, &comic.Title, &comic.Author, &comic.Description,
		&comic.Cover, &tagsJSON, &categoriesJSON, &comic.EpsCount,
		&comic.PagesCount, &comic.Type, &timeUnix, &comic.Size,
		&comic.Directory, &epsJSON, &downloadedEpsJSON, &comic.DetailURL,
	)

	if err != nil {
		// å¦‚æœæ•°æ®åº“ä¸­æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿæ‰«æ
		if err == sql.ErrNoRows {
			// è·å–æ‰€æœ‰æ¼«ç”»ï¼ˆåŒ…æ‹¬æ‰«æçš„ï¼‰
			allComics, scanErr := dm.GetAllComics()
			if scanErr != nil {
				return nil, err // è¿”å›åŸå§‹é”™è¯¯
			}

			// æŸ¥æ‰¾åŒ¹é…çš„æ¼«ç”»
			for _, c := range allComics {
				if c.ID == id {
					return &c, nil
				}
			}
		}
		return nil, err
	}

	// ç¡®ä¿å³ä½¿JSONä¸ºç©ºä¹Ÿåˆå§‹åŒ–ä¸ºç©ºæ•°ç»„
	if tagsJSON != "" {
		json.Unmarshal([]byte(tagsJSON), &comic.Tags)
	}
	if comic.Tags == nil {
		comic.Tags = []string{}
	}

	if categoriesJSON != "" {
		json.Unmarshal([]byte(categoriesJSON), &comic.Categories)
	}
	if comic.Categories == nil {
		comic.Categories = []string{}
	}

	if epsJSON != "" {
		json.Unmarshal([]byte(epsJSON), &comic.Eps)
	}
	if comic.Eps == nil {
		comic.Eps = []string{}
	}

	if downloadedEpsJSON != "" {
		json.Unmarshal([]byte(downloadedEpsJSON), &comic.DownloadedEps)
	}
	if comic.DownloadedEps == nil {
		comic.DownloadedEps = []int{}
	}

	comic.Time = time.Unix(timeUnix, 0)

	return &comic, nil
}

// GetCoverPath è·å–å°é¢è·¯å¾„
func (dm *DownloadManager) GetCoverPath(id string) (string, error) {
	comic, err := dm.GetComic(id)
	if err != nil {
		return "", err
	}

	coverPath := filepath.Join(dm.downloadPath, comic.Directory, "cover.jpg")
	if _, err := os.Stat(coverPath); os.IsNotExist(err) {
		return "", fmt.Errorf("å°é¢æ–‡ä»¶ä¸å­˜åœ¨")
	}

	return coverPath, nil
}

// GetEpisodePageCount è·å–ç« èŠ‚çš„é¡µé¢æ•°é‡
func (dm *DownloadManager) GetEpisodePageCount(id string, ep int) (int, error) {
	comic, err := dm.GetComic(id)
	if err != nil {
		return 0, err
	}

	var imagePath string
	if ep == 0 {
		// æ²¡æœ‰ç« èŠ‚çš„æ¼«ç”»
		imagePath = filepath.Join(dm.downloadPath, comic.Directory)
	} else {
		// æœ‰ç« èŠ‚çš„æ¼«ç”»
		imagePath = filepath.Join(dm.downloadPath, comic.Directory, fmt.Sprintf("%d", ep))
	}

	// è¯»å–ç›®å½•ä¸­çš„å›¾ç‰‡æ–‡ä»¶
	files, err := os.ReadDir(imagePath)
	if err != nil {
		return 0, err
	}

	// ç»Ÿè®¡å›¾ç‰‡æ–‡ä»¶æ•°é‡ï¼ˆæ’é™¤ cover.jpgï¼‰
	count := 0
	for _, file := range files {
		if file.IsDir() {
			continue
		}
		name := file.Name()
		// æ’é™¤å°é¢å’Œéå›¾ç‰‡æ–‡ä»¶
		if name == "cover.jpg" || name == "cover.png" {
			continue
		}
		ext := strings.ToLower(filepath.Ext(name))
		if ext == ".jpg" || ext == ".jpeg" || ext == ".png" || ext == ".webp" {
			count++
		}
	}

	return count, nil
}

// GetImagePath è·å–å›¾ç‰‡è·¯å¾„
func (dm *DownloadManager) GetImagePath(id string, ep int, page int) (string, error) {
	comic, err := dm.GetComic(id)
	if err != nil {
		return "", err
	}

	var imagePath string
	if ep == 0 {
		// æ²¡æœ‰ç« èŠ‚çš„æ¼«ç”»
		imagePath = filepath.Join(dm.downloadPath, comic.Directory)
	} else {
		// æœ‰ç« èŠ‚çš„æ¼«ç”»
		imagePath = filepath.Join(dm.downloadPath, comic.Directory, fmt.Sprintf("%d", ep))
	}

	// æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
	files, err := os.ReadDir(imagePath)
	if err != nil {
		return "", err
	}

	// å°è¯•å¤šç§é¡µé¢ç¼–å·æ ¼å¼
	pageFormats := []string{
		fmt.Sprintf("%03d", page), // 001, 002, ...
		fmt.Sprintf("%d", page),   // 1, 2, ...
		fmt.Sprintf("%02d", page), // 01, 02, ...
	}

	for _, file := range files {
		name := file.Name()
		nameWithoutExt := strings.TrimSuffix(name, filepath.Ext(name))

		for _, pageStr := range pageFormats {
			if nameWithoutExt == pageStr {
				return filepath.Join(imagePath, name), nil
			}
		}
	}

	return "", fmt.Errorf("å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: page=%d", page)
}

// DeleteComic åˆ é™¤æ¼«ç”»
func (dm *DownloadManager) DeleteComic(id string) error {
	comic, err := dm.GetComic(id)
	if err != nil {
		return err
	}

	// åˆ é™¤æ–‡ä»¶
	comicPath := filepath.Join(dm.downloadPath, comic.Directory)
	if err := os.RemoveAll(comicPath); err != nil {
		return err
	}

	// ä»æ•°æ®åº“åˆ é™¤
	_, err = dm.db.Exec("DELETE FROM comics WHERE id = ?", id)
	return err
}

// downloadFile ä¸‹è½½æ–‡ä»¶
func downloadFile(url string, filepath string) error {
	resp, err := http.Get(url)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	out, err := os.Create(filepath)
	if err != nil {
		return err
	}
	defer out.Close()

	_, err = io.Copy(out, resp.Body)
	return err
}

type TaskRepository struct {
	db           *sql.DB
	downloadPath string
}

func NewTaskRepository(db *sql.DB, downloadPath string) *TaskRepository {
	return &TaskRepository{db: db, downloadPath: downloadPath}
}

func (repo *TaskRepository) UpdateProgress(task *models.DownloadTask, downloadedPages int, currentEp int) error {
	task.DownloadedPages = downloadedPages
	task.CurrentEp = currentEp
	task.UpdatedAt = time.Now()
	_, err := repo.db.Exec(`
		UPDATE download_tasks 
		SET downloaded_pages = ?, current_ep = ?, updated_at = ?, status = ?
		WHERE id = ?
	`, task.DownloadedPages, task.CurrentEp, task.UpdatedAt.Unix(), task.Status, task.ID)
	return err
}

func (repo *TaskRepository) SaveComicDetail(comic *models.ComicDetail) error {
	tagsJSON, _ := json.Marshal(comic.Tags)
	categoriesJSON, _ := json.Marshal(comic.Categories)
	epsJSON, _ := json.Marshal(comic.Eps)
	downloadedEpsJSON, _ := json.Marshal(comic.DownloadedEps)

	_, err := repo.db.Exec(`
		INSERT INTO comics (
			id, title, author, description, cover, tags, categories,
			eps_count, pages_count, type, time, size, directory, eps, downloaded_eps, detail_url
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
		ON CONFLICT(id) DO UPDATE SET
			title = excluded.title,
			author = excluded.author,
			description = excluded.description,
			cover = excluded.cover,
			tags = excluded.tags,
			categories = excluded.categories,
			eps_count = excluded.eps_count,
			pages_count = excluded.pages_count,
			type = excluded.type,
			time = excluded.time,
			size = excluded.size,
			detail_url = excluded.detail_url,
			directory = excluded.directory,
			eps = excluded.eps,
			downloaded_eps = excluded.downloaded_eps
	`,
		comic.ID,
		comic.Title,
		comic.Author,
		comic.Description,
		comic.Cover,
		string(tagsJSON),
		string(categoriesJSON),
		comic.EpsCount,
		comic.PagesCount,
		comic.Type,
		comic.Time.Unix(),
		comic.Size,
		comic.Directory,
		string(epsJSON),
		string(downloadedEpsJSON),
		comic.DetailURL,
	)
	return err
}

func (repo *TaskRepository) SaveFile(path string, reader io.Reader) error {
	if err := os.MkdirAll(filepath.Dir(path), 0755); err != nil {
		return err
	}

	file, err := os.Create(path)
	if err != nil {
		return err
	}
	defer file.Close()

	_, err = io.Copy(file, reader)
	return err
}

func (repo *TaskRepository) SaveBytes(path string, data []byte) error {
	if err := os.MkdirAll(filepath.Dir(path), 0755); err != nil {
		return err
	}
	return os.WriteFile(path, data, 0644)
}

func (repo *TaskRepository) AppendDownloadedEp(comicID string, ep int) error {
	var downloaded string
	err := repo.db.QueryRow("SELECT downloaded_eps FROM comics WHERE id = ?", comicID).Scan(&downloaded)
	if err != nil && !errors.Is(err, sql.ErrNoRows) {
		return err
	}

	var eps []int
	if downloaded != "" {
		if err := json.Unmarshal([]byte(downloaded), &eps); err != nil {
			return err
		}
	}

	for _, existing := range eps {
		if existing == ep {
			return nil
		}
	}

	eps = append(eps, ep)
	data, _ := json.Marshal(eps)
	_, err = repo.db.Exec("UPDATE comics SET downloaded_eps = ? WHERE id = ?", string(data), comicID)
	return err
}

// SubmitDirectDownload æäº¤ç›´æ¥ä¸‹è½½ä»»åŠ¡ï¼ˆæ–¹æ¡ˆ2ï¼šå®¢æˆ·ç«¯å·²è·å–URLï¼‰
func (dm *DownloadManager) SubmitDirectDownload(reqData interface{}) (string, error) {
	// å› ä¸ºä¸èƒ½ç›´æ¥å¯¼å…¥ handlers åŒ…ï¼ˆä¼šå¾ªç¯ä¾èµ–ï¼‰ï¼Œæ‰€ä»¥ç”¨åå°„å¤„ç†
	data, err := json.Marshal(reqData)
	if err != nil {
		return "", err
	}

	var req struct {
		ComicID     string              `json:"comic_id"`
		Type        string              `json:"type"`
		Title       string              `json:"title"`
		Cover       string              `json:"cover"`
		Author      string              `json:"author"`
		Description string              `json:"description"`
		DetailURL   string              `json:"detail_url"` // è¯¦æƒ…é¡µé“¾æ¥
		Tags        map[string][]string `json:"tags"`
		Episodes    []struct {
			Order    int               `json:"order"`
			Name     string            `json:"name"`
			PageURLs []string          `json:"page_urls"`
			Headers  map[string]string `json:"headers"` // å®¢æˆ·ç«¯æä¾›çš„ HTTP headers
		} `json:"episodes"`
	}

	if err := json.Unmarshal(data, &req); err != nil {
		return "", err
	}

	dm.mu.Lock()
	defer dm.mu.Unlock()

	// æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„ä¸‹è½½ä»»åŠ¡ï¼ˆé˜Ÿåˆ—ä¸­ï¼‰
	for _, existingTask := range dm.queue {
		if existingTask.ComicID == req.ComicID &&
			(existingTask.Status == "pending" || existingTask.Status == "downloading" || existingTask.Status == "paused") {
			log.Printf("[DownloadManager] æ¼«ç”» %s å·²åœ¨ä¸‹è½½é˜Ÿåˆ—ä¸­ï¼Œä»»åŠ¡ID: %sï¼ŒçŠ¶æ€: %s",
				req.ComicID, existingTask.ID, existingTask.Status)
			return existingTask.ID, nil
		}
	}

	// æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰æœªå®Œæˆçš„ä»»åŠ¡
	var existingTaskID string
	err = dm.db.QueryRow(`
		SELECT id FROM download_tasks 
		WHERE comic_id = ? AND status IN ('pending', 'downloading', 'paused')
		LIMIT 1
	`, req.ComicID).Scan(&existingTaskID)

	if err == nil {
		// æ‰¾åˆ°äº†ç°æœ‰ä»»åŠ¡
		log.Printf("[DownloadManager] æ•°æ®åº“ä¸­å·²æœ‰æ¼«ç”» %s çš„ä¸‹è½½ä»»åŠ¡: %s", req.ComicID, existingTaskID)
		return existingTaskID, nil
	}

	// åˆ›å»ºä»»åŠ¡
	taskID := fmt.Sprintf("direct_%d", time.Now().UnixNano())

	title := req.Title
	if title == "" {
		title = "æœªå‘½åæ¼«ç”»"
	}

	// è®¡ç®—æ€»é¡µæ•°
	totalPages := 0
	for _, ep := range req.Episodes {
		totalPages += len(ep.PageURLs)
	}

	task := &models.DownloadTask{
		ID:              taskID,
		ComicID:         req.ComicID,
		Type:            req.Type,
		Title:           title,
		Cover:           req.Cover,
		Description:     req.Description,
		Author:          req.Author,
		Status:          "pending",
		TotalPages:      totalPages,
		DownloadedPages: 0,
		CreatedAt:       time.Now(),
		UpdatedAt:       time.Now(),
	}

	// å°† episodes æ•°æ®å’Œ detail_url å­˜å…¥ Extra
	extraData := map[string]interface{}{
		"direct_mode": true,
		"episodes":    req.Episodes,
		"detail_url":  req.DetailURL,
	}
	extraJSON, _ := json.Marshal(extraData)
	task.Extra = string(extraJSON)

	// ä¿å­˜åˆ°æ•°æ®åº“
	tagsJSON, _ := json.Marshal(req.Tags)
	task.Tags = string(tagsJSON)

	_, err = dm.db.Exec(`
		INSERT INTO download_tasks 
		(id, comic_id, type, title, status, cover, description, tags, author, extra, downloaded_pages, total_pages, current_ep, created_at, updated_at)
		VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`, task.ID, task.ComicID, task.Type, task.Title, task.Status,
		task.Cover, task.Description, task.Tags, task.Author,
		task.Extra, task.DownloadedPages, task.TotalPages, task.CurrentEp,
		task.CreatedAt.Unix(), task.UpdatedAt.Unix())

	if err != nil {
		return "", err
	}

	log.Printf("[DownloadManager] åˆ›å»ºæ–°ä¸‹è½½ä»»åŠ¡: %s, æ¼«ç”»ID: %s, æ ‡é¢˜: %s", taskID, req.ComicID, title)

	// åŠ å…¥ä¸‹è½½é˜Ÿåˆ—
	dm.queue = append(dm.queue, task)

	go dm.processQueue()

	return taskID, nil
}

// sanitizeFolderName å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå®‰å…¨çš„æ–‡ä»¶å¤¹åç§°
// ä½¿ç”¨ä¸å®¢æˆ·ç«¯ç›¸åŒçš„è§„åˆ™
func sanitizeFolderName(name string) string {
	// 1. æ›¿æ¢éæ³•å­—ç¬¦ä¸ºç©ºæ ¼ï¼ˆä¸å®¢æˆ·ç«¯ä¸€è‡´ï¼‰
	replacer := strings.NewReplacer(
		"<", " ",
		">", " ",
		":", " ",
		"\"", " ",
		"/", " ",
		"\\", " ",
		"|", " ",
		"?", " ",
		"*", " ",
	)
	safe := replacer.Replace(name)

	// 2. å»é™¤é¦–å°¾ç©ºæ ¼
	safe = strings.TrimSpace(safe)

	// 3. é™åˆ¶é•¿åº¦ä¸º 255 å­—èŠ‚ï¼ˆä¸å®¢æˆ·ç«¯ä¸€è‡´ï¼‰
	// é€å­—ç¬¦åˆ é™¤æœ«å°¾ï¼Œé¿å…ç ´å UTF-8 ç¼–ç 
	for len(safe) > 0 && len([]byte(safe)) > 255 {
		runes := []rune(safe)
		safe = string(runes[:len(runes)-1])
	}

	// å¦‚æœä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
	if safe == "" {
		safe = "untitled"
	}

	return safe
}

// extractBookIdFromUrl ä» JM å›¾ç‰‡ URL ä¸­æå– bookId
// ä¸å®¢æˆ·ç«¯é€»è¾‘ä¸€è‡´ï¼š
// 1. url.substring(i + 1, url.length - 5)
// 2. bookId.replaceAll(RegExp(r"\..+"), "")
func extractBookIdFromUrl(url string) string {
	// JM URL æ ¼å¼: https://cdn.../photos/12345/abc123.webp
	// å®¢æˆ·ç«¯é€»è¾‘ï¼šä»æœ€åä¸€ä¸ª / ä¹‹åå¼€å§‹ï¼Œå»æ‰æœ€å5ä¸ªå­—ç¬¦ï¼ˆ.webpï¼‰
	
	// å…ˆç§»é™¤æŸ¥è¯¢å‚æ•°
	url = strings.Split(url, "?")[0]
	
	// æ‰¾åˆ°æœ€åä¸€ä¸ª /
	lastSlash := strings.LastIndex(url, "/")
	if lastSlash == -1 || lastSlash == len(url)-1 {
		return ""
	}
	
	// æå–æ–‡ä»¶åéƒ¨åˆ†
	filename := url[lastSlash+1:]
	
	// å»æ‰æœ€å5ä¸ªå­—ç¬¦ï¼ˆä¸å®¢æˆ·ç«¯ä¸€è‡´ï¼‰
	if len(filename) > 5 {
		filename = filename[:len(filename)-5]
	}
	
	// ç§»é™¤ç¬¬ä¸€ä¸ª . ä¹‹åçš„æ‰€æœ‰å†…å®¹ï¼ˆä¸å®¢æˆ·ç«¯ä¸€è‡´ï¼‰
	if dotIndex := strings.Index(filename, "."); dotIndex != -1 {
		filename = filename[:dotIndex]
	}
	
	return filename
}

// downloadDirectComic ç›´æ¥ä¸‹è½½æ¨¡å¼ï¼ˆå®¢æˆ·ç«¯å·²è·å–URLï¼‰
func (dm *DownloadManager) downloadDirectComic(task *models.DownloadTask) error {
	// è§£æ Extra ä¸­çš„ episodes æ•°æ®å’Œ detail_url
	var extra struct {
		DirectMode bool   `json:"direct_mode"`
		DetailURL  string `json:"detail_url"` // è¯¦æƒ…é¡µé“¾æ¥
		Episodes   []struct {
			Order            int               `json:"order"`
			Name             string            `json:"name"`
			PageURLs         []string          `json:"page_urls"`
			Headers          map[string]string `json:"headers"`           // å®¢æˆ·ç«¯æä¾›çš„ HTTP headers
			DescrambleParams map[string]string `json:"descramble_params"` // åæ··æ·†å‚æ•°ï¼ˆå¯é€‰ï¼‰
		} `json:"episodes"`
	}

	if err := json.Unmarshal([]byte(task.Extra), &extra); err != nil {
		return fmt.Errorf("è§£æä»»åŠ¡æ•°æ®å¤±è´¥: %w", err)
	}

	if !extra.DirectMode {
		return fmt.Errorf("ä¸æ˜¯ç›´æ¥ä¸‹è½½æ¨¡å¼")
	}

	repo := NewTaskRepository(dm.db, dm.downloadPath)

	// ä½¿ç”¨æ¼«ç”»æ ‡é¢˜ä½œä¸ºæ–‡ä»¶å¤¹åï¼ˆå®‰å…¨åŒ–å¤„ç†ï¼‰
	baseFolderName := sanitizeFolderName(task.Title)
	folderName := baseFolderName

	// æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™æ·»åŠ æ•°å­—åç¼€
	counter := 1
	for {
		testPath := filepath.Join(dm.downloadPath, folderName)
		if _, err := os.Stat(testPath); os.IsNotExist(err) {
			// æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œå¯ä»¥ä½¿ç”¨
			break
		}
		// æ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ªåå­—
		counter++
		folderName = fmt.Sprintf("%s_%d", baseFolderName, counter)
	}

	downloadDir := filepath.Join(dm.downloadPath, folderName)
	if err := os.MkdirAll(downloadDir, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºä¸‹è½½ç›®å½•å¤±è´¥: %w", err)
	}

	// è·å–è¯¥æ¼«ç”»ç±»å‹çš„å›¾ç‰‡è¯·æ±‚å¤´
	imageHeaders := dm.getImageHeaders(task.Type, "")

	// ä¸‹è½½å°é¢
	if task.Cover != "" {
		fmt.Printf("[ç›´æ¥ä¸‹è½½] ä¸‹è½½å°é¢: %s\n", task.Cover)
		coverPath := filepath.Join(downloadDir, "cover.jpg")
		if err := dm.downloadFileWithHeaders(task.Cover, coverPath, imageHeaders); err != nil {
			fmt.Printf("[è­¦å‘Š] å°é¢ä¸‹è½½å¤±è´¥: %v\n", err)
			// å°é¢ä¸‹è½½å¤±è´¥ä¸é˜»æ­¢æ•´ä¸ªä»»åŠ¡
		} else {
			fmt.Printf("[ç›´æ¥ä¸‹è½½] âœ… å°é¢ä¸‹è½½æˆåŠŸ\n")
		}
	}

	downloadedPages := 0

	fmt.Printf("[ç›´æ¥ä¸‹è½½] å¼€å§‹ä¸‹è½½ %d ä¸ªç« èŠ‚...\n", len(extra.Episodes))
	for _, ep := range extra.Episodes {
		epDir := filepath.Join(downloadDir, fmt.Sprintf("%d", ep.Order))
		if err := os.MkdirAll(epDir, 0755); err != nil {
			return fmt.Errorf("åˆ›å»ºç« èŠ‚ç›®å½•å¤±è´¥: %w", err)
		}

		fmt.Printf("[ç›´æ¥ä¸‹è½½] ç« èŠ‚ %d (%s) å…±æœ‰ %d å¼ å›¾ç‰‡\n", ep.Order, ep.Name, len(ep.PageURLs))

		// ä¼˜å…ˆä½¿ç”¨å®¢æˆ·ç«¯æä¾›çš„ headersï¼Œå¦åˆ™ä½¿ç”¨æœåŠ¡å™¨ç«¯é»˜è®¤çš„
		episodeHeaders := imageHeaders
		if ep.Headers != nil && len(ep.Headers) > 0 {
			episodeHeaders = ep.Headers
			fmt.Printf("[ç›´æ¥ä¸‹è½½] ä½¿ç”¨å®¢æˆ·ç«¯æä¾›çš„ headers: %d ä¸ª\n", len(episodeHeaders))
		} else {
			fmt.Printf("[ç›´æ¥ä¸‹è½½] ä½¿ç”¨æœåŠ¡å™¨ç«¯é»˜è®¤ headers\n")
		}

		for index, pageURL := range ep.PageURLs {
			filePath := filepath.Join(epDir, fmt.Sprintf("%03d.jpg", index+1))
			fmt.Printf("[ç›´æ¥ä¸‹è½½] æ­£åœ¨ä¸‹è½½ç« èŠ‚ %d ç¬¬ %d/%d é¡µ\n", ep.Order, index+1, len(ep.PageURLs))

			// ä½¿ç”¨ç« èŠ‚å¯¹åº”çš„è¯·æ±‚å¤´ä¸‹è½½å›¾ç‰‡
			if err := dm.downloadFileWithHeaders(pageURL, filePath, episodeHeaders); err != nil {
				fmt.Printf("[é”™è¯¯] ä¸‹è½½å¤±è´¥: %v\n", err)
				return fmt.Errorf("ä¸‹è½½ç« èŠ‚ %d ç¬¬ %d é¡µå¤±è´¥: %w", ep.Order, index+1, err)
			}

			// éªŒè¯æ–‡ä»¶å¤§å°
			info, _ := os.Stat(filePath)
			if info.Size() < 100 {
				return fmt.Errorf("ä¸‹è½½çš„æ–‡ä»¶è¿‡å°ï¼ˆå¯èƒ½å¤±è´¥ï¼‰: %d bytes", info.Size())
			}

			// ç¨å¾®ç­‰å¾…ç¡®ä¿æ–‡ä»¶å®Œå…¨å†™å…¥ç£ç›˜
			time.Sleep(10 * time.Millisecond)

			// å¦‚æœæœ‰åæ··æ·†å‚æ•°ï¼Œè¿›è¡Œåæ··æ·†å¤„ç†
			if ep.DescrambleParams != nil && len(ep.DescrambleParams) > 0 {
				epsId := ep.DescrambleParams["epsId"]
				scrambleId := ep.DescrambleParams["scrambleId"]

				// ä» URL ä¸­æå– bookId
				bookId := extractBookIdFromUrl(pageURL)

				fmt.Printf("[åæ··æ·†] å¤„ç†å›¾ç‰‡: epsId=%s, scrambleId=%s, bookId=%s\n", epsId, scrambleId, bookId)
				if err := DescrambleJmImage(filePath, epsId, scrambleId, bookId); err != nil {
					fmt.Printf("[è­¦å‘Š] å›¾ç‰‡åæ··æ·†å¤±è´¥: %v\n", err)
					// ä¸ä¸­æ–­ä¸‹è½½ï¼Œç»§ç»­å¤„ç†å…¶ä»–å›¾ç‰‡
				} else {
					fmt.Printf("[åæ··æ·†] âœ… å›¾ç‰‡åæ··æ·†æˆåŠŸ\n")
				}
			}

			downloadedPages++
			task.DownloadedPages = downloadedPages
			task.CurrentEp = ep.Order
			dm.updateTaskStatus(task)
		}

		// ä¿å­˜ç« èŠ‚ä¿¡æ¯
		if err := repo.AppendDownloadedEp(task.ComicID, ep.Order); err != nil {
			fmt.Printf("[è­¦å‘Š] ä¿å­˜ç« èŠ‚ä¿¡æ¯å¤±è´¥: %v\n", err)
		}
	}

	// ä¿å­˜æ¼«ç”»è¯¦æƒ…
	// è§£ææ ‡ç­¾å’Œåˆ†ç±»
	allTags, categories := parseTags(task.Tags)

	var epNames []string
	var epOrders []int
	for _, ep := range extra.Episodes {
		epNames = append(epNames, ep.Name)
		epOrders = append(epOrders, ep.Order)
	}

	// è®¡ç®—æ¼«ç”»æ–‡ä»¶å¤¹å¤§å°
	folderSize := calculateFolderSize(downloadDir)

	detail := &models.ComicDetail{
		Comic: models.Comic{
			ID:          task.ComicID,
			Title:       task.Title,
			Cover:       task.Cover,
			Author:      task.Author,
			Description: task.Description,
			Tags:        allTags,    // æ‰€æœ‰æ ‡ç­¾
			Categories:  categories, // åˆ†ç±»ï¼ˆä»tagsä¸­æå–çš„categoryé”®ï¼‰
			Type:        task.Type,
			EpsCount:    len(extra.Episodes),
			PagesCount:  task.TotalPages,
			Size:        folderSize, // è®¡ç®—çš„å®é™…å¤§å°ï¼ˆå­—èŠ‚ï¼‰
			Time:        time.Now(),
			DetailURL:   extra.DetailURL, // è¯¦æƒ…é¡µé“¾æ¥
		},
		Directory:     folderName, // ä½¿ç”¨å®‰å…¨çš„æ–‡ä»¶å¤¹åç§°
		Eps:           epNames,
		DownloadedEps: epOrders,
	}

	if err := repo.SaveComicDetail(detail); err != nil {
		return fmt.Errorf("ä¿å­˜æ¼«ç”»è¯¦æƒ…å¤±è´¥: %w", err)
	}

	fmt.Printf("[ç›´æ¥ä¸‹è½½] âœ… ä¸‹è½½å®Œæˆï¼\n")
	return nil
}

// ImportComicFromClient ä»å®¢æˆ·ç«¯å¯¼å…¥å·²ä¸‹è½½çš„æ¼«ç”»
func (dm *DownloadManager) ImportComicFromClient(r *http.Request, comicID, title, comicType, author, description, coverURL string) error {
	fmt.Printf("[å¯¼å…¥] å¼€å§‹å¯¼å…¥æ¼«ç”»: %s\n", title)

	repo := NewTaskRepository(dm.db, dm.downloadPath)

	// 1. åˆ›å»ºæ¼«ç”»ç›®å½•
	folderName := sanitizeFolderName(title)
	counter := 1
	for {
		testPath := filepath.Join(dm.downloadPath, folderName)
		if _, err := os.Stat(testPath); os.IsNotExist(err) {
			break
		}
		counter++
		folderName = fmt.Sprintf("%s_%d", sanitizeFolderName(title), counter)
	}

	comicDir := filepath.Join(dm.downloadPath, folderName)
	if err := os.MkdirAll(comicDir, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºç›®å½•å¤±è´¥: %w", err)
	}

	// 2. è·å–ä¸Šä¼ çš„æ–‡ä»¶
	form := r.MultipartForm
	if form == nil {
		return fmt.Errorf("æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
	}

	files := form.File["files"]
	if len(files) == 0 {
		return fmt.Errorf("æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
	}

	// 3. è§£æç« èŠ‚ç»“æ„å¹¶ä¿å­˜æ–‡ä»¶
	// å®¢æˆ·ç«¯ä¸Šä¼ æ ¼å¼: ep1_page001.jpg, ep1_page002.jpg, ep2_page001.jpg, ...
	// æˆ– cover.jpg
	episodeMap := make(map[int][]string) // ep -> é¡µé¢æ–‡ä»¶åˆ—è¡¨
	var epsCount, totalPages int

	fmt.Printf("[å¯¼å…¥] å¼€å§‹å¤„ç† %d ä¸ªä¸Šä¼ æ–‡ä»¶...\n", len(files))

	for _, fileHeader := range files {
		// æ‰“å¼€ä¸Šä¼ çš„æ–‡ä»¶
		file, err := fileHeader.Open()
		if err != nil {
			fmt.Printf("[è­¦å‘Š] æ‰“å¼€æ–‡ä»¶å¤±è´¥: %v\n", err)
			continue
		}

		filename := fileHeader.Filename
		fmt.Printf("[å¯¼å…¥] å¤„ç†æ–‡ä»¶: %s\n", filename)

		// ä¿å­˜å°é¢
		if filename == "cover.jpg" || filename == "cover.png" {
			ext := filepath.Ext(filename)
			coverPath := filepath.Join(comicDir, "cover"+ext)
			if err := saveUploadedFile(file, coverPath); err != nil {
				fmt.Printf("[è­¦å‘Š] ä¿å­˜å°é¢å¤±è´¥: %v\n", err)
			} else {
				fmt.Printf("[å¯¼å…¥] âœ… å°é¢å·²ä¿å­˜: %s\n", coverPath)
			}
			file.Close()
			continue
		}

		// è§£æç« èŠ‚å’Œé¡µé¢ä¿¡æ¯ (æ ¼å¼: ep1_page001.jpg æˆ– ep1_page001.png)
		// ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…ä¸åŒçš„æ‰©å±•å
		var epNum, pageNum int
		var ext string

		// å°è¯•è§£ææ–‡ä»¶å
		matched := false
		for _, pattern := range []string{".jpg", ".jpeg", ".png", ".webp", ".gif"} {
			testName := strings.TrimSuffix(filename, pattern)
			n, err := fmt.Sscanf(testName, "ep%d_page%03d", &epNum, &pageNum)
			if err == nil && n == 2 {
				ext = pattern
				matched = true
				break
			}
		}

		if !matched {
			fmt.Printf("[è­¦å‘Š] æ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®: %s (æ— æ³•è§£æç« èŠ‚å’Œé¡µé¢ä¿¡æ¯)\n", filename)
			file.Close()
			continue
		}

		fmt.Printf("[å¯¼å…¥] è§£ææˆåŠŸ: ç« èŠ‚ %d, é¡µé¢ %d, æ‰©å±•å %s\n", epNum, pageNum, ext)

		// åˆ›å»ºç« èŠ‚ç›®å½•
		epDir := filepath.Join(comicDir, fmt.Sprintf("%d", epNum))
		if err := os.MkdirAll(epDir, 0755); err != nil {
			file.Close()
			return fmt.Errorf("åˆ›å»ºç« èŠ‚ç›®å½•å¤±è´¥: %w", err)
		}

		// ä¿å­˜å›¾ç‰‡ï¼Œä¿ç•™åŸå§‹æ‰©å±•å
		imagePath := filepath.Join(epDir, fmt.Sprintf("%03d%s", pageNum, ext))
		if err := saveUploadedFile(file, imagePath); err != nil {
			file.Close()
			return fmt.Errorf("ä¿å­˜å›¾ç‰‡å¤±è´¥: %w", err)
		}
		fmt.Printf("[å¯¼å…¥] âœ… å›¾ç‰‡å·²ä¿å­˜: %s\n", imagePath)
		file.Close()

		// è®°å½•ç« èŠ‚ä¿¡æ¯
		if _, exists := episodeMap[epNum]; !exists {
			episodeMap[epNum] = []string{}
			epsCount++
		}
		episodeMap[epNum] = append(episodeMap[epNum], imagePath)
		totalPages++
	}

	fmt.Printf("[å¯¼å…¥] æ–‡ä»¶å¤„ç†å®Œæˆ: %d ä¸ªç« èŠ‚, %d é¡µ\n", epsCount, totalPages)

	// 4. æ„å»ºç« èŠ‚åˆ—è¡¨
	var epOrders []int
	for ep := range episodeMap {
		epOrders = append(epOrders, ep)
	}
	sort.Ints(epOrders)

	// å°è¯•ä»å®¢æˆ·ç«¯è·å–ç« èŠ‚åç§°åˆ—è¡¨
	var epNames []string
	epsJSON := r.PostFormValue("eps")
	if epsJSON != "" {
		if err := json.Unmarshal([]byte(epsJSON), &epNames); err != nil {
			fmt.Printf("[è­¦å‘Š] è§£æç« èŠ‚åç§°å¤±è´¥: %v\n", err)
			// å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åç§°
			for _, ep := range epOrders {
				epNames = append(epNames, fmt.Sprintf("ç¬¬ %d è¯", ep))
			}
		}
	} else {
		// æ²¡æœ‰æä¾›ç« èŠ‚åç§°ï¼Œä½¿ç”¨é»˜è®¤åç§°
		for _, ep := range epOrders {
			epNames = append(epNames, fmt.Sprintf("ç¬¬ %d è¯", ep))
		}
	}

	// 5. è§£ææ ‡ç­¾å’Œåˆ†ç±»
	tagsJSON := r.PostFormValue("tags")
	allTags, categories := parseTags(tagsJSON)

	// 6. è·å–ä¸‹è½½æ—¶é—´
	var downloadTime time.Time
	downloadTimeStr := r.PostFormValue("download_time")
	if downloadTimeStr != "" {
		parsedTime, err := time.Parse(time.RFC3339, downloadTimeStr)
		if err == nil {
			downloadTime = parsedTime
		} else {
			downloadTime = time.Now()
		}
	} else {
		downloadTime = time.Now()
	}

	// 7. ä¿å­˜åˆ°æ•°æ®åº“
	// è®¡ç®—æ¼«ç”»æ–‡ä»¶å¤¹å¤§å°
	folderSize := calculateFolderSize(comicDir)

	detail := &models.ComicDetail{
		Comic: models.Comic{
			ID:          comicID,
			Title:       title,
			Cover:       coverURL,
			Author:      author,
			Description: description,
			Tags:        allTags,    // æ‰€æœ‰æ ‡ç­¾
			Categories:  categories, // åˆ†ç±»ï¼ˆä»tagsä¸­æå–çš„categoryé”®ï¼‰
			Type:        comicType,
			EpsCount:    epsCount,
			PagesCount:  totalPages,
			Size:        folderSize,   // è®¡ç®—çš„å®é™…å¤§å°ï¼ˆå­—èŠ‚ï¼‰
			Time:        downloadTime, // ä½¿ç”¨å®¢æˆ·ç«¯æä¾›çš„ä¸‹è½½æ—¶é—´
		},
		Directory:     folderName,
		Eps:           epNames,
		DownloadedEps: epOrders,
	}

	if err := repo.SaveComicDetail(detail); err != nil {
		return fmt.Errorf("ä¿å­˜æ¼«ç”»è¯¦æƒ…å¤±è´¥: %w", err)
	}

	fmt.Printf("[å¯¼å…¥] âœ… å¯¼å…¥å®Œæˆï¼å…± %d ä¸ªç« èŠ‚ï¼Œ%d é¡µï¼Œå¤§å° %.2f MB\n", epsCount, totalPages, float64(folderSize)/(1024*1024))
	return nil
}

// saveUploadedFile ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
func saveUploadedFile(src multipart.File, dst string) error {
	out, err := os.Create(dst)
	if err != nil {
		return err
	}
	defer out.Close()

	_, err = io.Copy(out, src)
	return err
}

// calculateFolderSize è®¡ç®—æ–‡ä»¶å¤¹å¤§å°ï¼ˆå­—èŠ‚ï¼‰
func calculateFolderSize(path string) int64 {
	var size int64
	err := filepath.Walk(path, func(_ string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.IsDir() {
			size += info.Size()
		}
		return nil
	})
	if err != nil {
		fmt.Printf("[è­¦å‘Š] è®¡ç®—æ–‡ä»¶å¤¹å¤§å°å¤±è´¥: %v\n", err)
		return 0
	}
	return size
}
